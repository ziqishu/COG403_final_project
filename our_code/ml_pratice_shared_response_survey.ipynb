{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# support vector machine\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "# classification report\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 19464 entries, 0 to 23732\n",
      "Data columns (total 28 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   ResponseID               19464 non-null  object \n",
      " 1   ExtendedSessionID        19464 non-null  object \n",
      " 2   UserID                   19464 non-null  float64\n",
      " 3   ScenarioOrder            19464 non-null  int64  \n",
      " 4   Intervention             19464 non-null  int64  \n",
      " 5   PedPed                   19464 non-null  int64  \n",
      " 6   Barrier                  19464 non-null  int64  \n",
      " 7   CrossingSignal           19464 non-null  int64  \n",
      " 8   AttributeLevel           19464 non-null  object \n",
      " 9   ScenarioTypeStrict       19464 non-null  object \n",
      " 10  ScenarioType             19464 non-null  object \n",
      " 11  DefaultChoice            19464 non-null  object \n",
      " 12  NonDefaultChoice         19464 non-null  object \n",
      " 13  DefaultChoiceIsOmission  19464 non-null  float64\n",
      " 14  NumberOfCharacters       19464 non-null  int64  \n",
      " 15  DiffNumberOFCharacters   19464 non-null  int64  \n",
      " 16  Saved                    19464 non-null  int64  \n",
      " 17  Template                 19464 non-null  object \n",
      " 18  DescriptionShown         19464 non-null  float64\n",
      " 19  LeftHand                 19464 non-null  float64\n",
      " 20  UserCountry3             19464 non-null  object \n",
      " 21  Review_age               19464 non-null  float64\n",
      " 22  Review_education         19464 non-null  object \n",
      " 23  Review_gender            19464 non-null  object \n",
      " 24  Review_income            19464 non-null  object \n",
      " 25  Review_political         19464 non-null  float64\n",
      " 26  Review_religious         19464 non-null  float64\n",
      " 27  political_category       19464 non-null  int64  \n",
      "dtypes: float64(7), int64(9), object(12)\n",
      "memory usage: 4.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('SharedResponsesSurvey_sample.csv')\n",
    "df = df.dropna()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the first three columns and the last column\n",
    "df_x = df.iloc[:, 3:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert string to float\n",
    "df_x = df_x.apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "\n",
    "# deal with inf and -inf\n",
    "df_x = df_x.replace([float('inf'), float('-inf')], float('nan'))\n",
    "\n",
    "# deal with too large values\n",
    "df_x = df_x.apply(lambda x: x.clip(lower=-1e10, upper=1e10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = df_x.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AttributeLevel', 'ScenarioTypeStrict', 'ScenarioType', 'DefaultChoice',\n",
       "       'NonDefaultChoice', 'Template', 'UserCountry3', 'Review_education',\n",
       "       'Review_gender', 'Review_income'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the columns with strings\n",
    "str_columns = df_x.select_dtypes(include=['object']).columns\n",
    "str_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy:  0.6791677369637812\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68      1934\n",
      "           1       0.68      0.68      0.68      1959\n",
      "\n",
      "    accuracy                           0.68      3893\n",
      "   macro avg       0.68      0.68      0.68      3893\n",
      "weighted avg       0.68      0.68      0.68      3893\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train machine learning model\n",
    "# Saved column is the target column\n",
    "df_y = df['Saved']\n",
    "# drop the target column\n",
    "df_x = df_x.drop('Saved', axis=1)\n",
    "\n",
    "# split the data into training and testing data\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.2, random_state=0)\n",
    "\n",
    "# random forest\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(x_train, y_train)\n",
    "rf_predict = rf.predict(x_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predict)\n",
    "print('Random Forest Accuracy: ', rf_accuracy)\n",
    "print(classification_report(y_test, rf_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy:  0.5032108913434369\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1934\n",
      "           1       0.50      1.00      0.67      1959\n",
      "\n",
      "    accuracy                           0.50      3893\n",
      "   macro avg       0.25      0.50      0.33      3893\n",
      "weighted avg       0.25      0.50      0.34      3893\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ziqi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Ziqi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Ziqi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# try logistic regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, y_train)\n",
    "lr_predict = lr.predict(x_test)\n",
    "lr_accuracy = accuracy_score(y_test, lr_predict)\n",
    "print('Logistic Regression Accuracy: ', lr_accuracy)\n",
    "print(classification_report(y_test, lr_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine Accuracy:  0.5032108913434369\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1934\n",
      "           1       0.50      1.00      0.67      1959\n",
      "\n",
      "    accuracy                           0.50      3893\n",
      "   macro avg       0.25      0.50      0.33      3893\n",
      "weighted avg       0.25      0.50      0.34      3893\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ziqi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Ziqi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Ziqi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# try support vector machine\n",
    "svm = SVC()\n",
    "svm.fit(x_train, y_train)\n",
    "svm_predict = svm.predict(x_test)\n",
    "svm_accuracy = accuracy_score(y_test, svm_predict)\n",
    "print('Support Vector Machine Accuracy: ', svm_accuracy)\n",
    "print(classification_report(y_test, svm_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy:  0.6750577960441818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.68      0.67      1934\n",
      "           1       0.68      0.67      0.68      1959\n",
      "\n",
      "    accuracy                           0.68      3893\n",
      "   macro avg       0.68      0.68      0.68      3893\n",
      "weighted avg       0.68      0.68      0.68      3893\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1306,  628],\n",
       "       [ 637, 1322]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "# try random forest\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(x_train, y_train)\n",
    "rf_predict = rf.predict(x_test)\n",
    "\n",
    "rf_accuracy = accuracy_score(y_test, rf_predict)\n",
    "print('Random Forest Accuracy: ', rf_accuracy)\n",
    "print(classification_report(y_test, rf_predict))\n",
    "\n",
    "# confusion matrix\n",
    "confusion_matrix(y_test, rf_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy:  0.6010788594913948\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.59      0.60      1934\n",
      "           1       0.60      0.61      0.61      1959\n",
      "\n",
      "    accuracy                           0.60      3893\n",
      "   macro avg       0.60      0.60      0.60      3893\n",
      "weighted avg       0.60      0.60      0.60      3893\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(x_train, y_train)\n",
    "dt_predict = dt.predict(x_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predict)\n",
    "print('Decision Tree Accuracy: ', dt_accuracy)\n",
    "print(classification_report(y_test, dt_predict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
